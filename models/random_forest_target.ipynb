{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import cross_validate, train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.metrics import mean_squared_error, r2_score, accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../data/new_train.csv')\n",
    "test = pd.read_csv('../data/new_test.csv')\n",
    "mcf = pd.read_csv('../data/monthly_card_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop(columns=['Unnamed: 0', 'first_active_month']).set_index('card_id')\n",
    "test = test.drop(columns=['Unnamed: 0', 'first_active_month']).set_index('card_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaelfedell/anaconda3/lib/python3.7/site-packages/pandas/core/reshape/merge.py:522: UserWarning: merging between different levels can give an unintended result (1 levels on the left, 2 on the right)\n",
      "  warnings.warn(msg, UserWarning)\n",
      "/Users/michaelfedell/anaconda3/lib/python3.7/site-packages/pandas/core/reshape/merge.py:522: UserWarning: merging between different levels can give an unintended result (1 levels on the left, 2 on the right)\n",
      "  warnings.warn(msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "train = train.join(mcf.groupby('card_id').agg({\n",
    "    'amt_total': [np.min, np.mean, np.max],\n",
    "    'NDR':       [np.min, np.mean, np.max],\n",
    "    'n_new_merchants':   np.mean,\n",
    "    'n_total_merchants': np.max\n",
    "}))\n",
    "test = test.join(mcf.groupby('card_id').agg({\n",
    "    'amt_total': [np.min, np.mean, np.max],\n",
    "    'NDR':       [np.min, np.mean, np.max],\n",
    "    'n_new_merchants':   np.mean,\n",
    "    'n_total_merchants': np.max\n",
    "}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.columns = ['_'.join(col).strip() if isinstance(col, tuple) else col for col in train.columns.values]\n",
    "test.columns = ['_'.join(col).strip() if isinstance(col, tuple) else col for col in test.columns.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['feature_1', 'feature_2', 'feature_3', 'tof', 'recency', 'frequency',\n",
       "       'log_freq', 'amt', 'avg_amt', 'charge_per_day', 'log_charge_per_day',\n",
       "       'max_amt', 'n_declines', 'log_n_declines', 'prop_new', 'merch_cat_1_Y',\n",
       "       'merch_cat_2_1', 'merch_cat_2_2', 'merch_cat_2_3', 'merch_cat_2_4',\n",
       "       'merch_cat_2_5', 'amt_total_amin', 'amt_total_mean', 'amt_total_amax',\n",
       "       'NDR_amin', 'NDR_mean', 'NDR_amax', 'n_new_merchants_mean',\n",
       "       'n_total_merchants_amax'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = train.drop(columns='target')\n",
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = train['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60576, 29)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size=0.3)\n",
    "X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfr = RandomForestRegressor(max_depth=5, random_state=0, n_estimators=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=5,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=None,\n",
       "           oob_score=False, random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfr.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Root Mean squared error: %.2f\"\n",
    "      % np.sqrt(mean_squared_error(Y_val, rfr.predict(X_val))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What if we bring in our chump-classifier?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['chump'] = train['target'] < -20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chumps = train[train.chump]\n",
    "nonchumps = train[~train.chump]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_chumps, tt_chumps = train_test_split(chumps, test_size=0.3)\n",
    "tr_nonchumps, tt_nonchumps = train_test_split(nonchumps, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr = pd.concat([tr_chumps, tr_nonchumps])\n",
    "tt = pd.concat([tt_chumps, tt_nonchumps])\n",
    "print('Training chumps:', sum(tr.chump)/len(tr))\n",
    "print('Test chumps:    ', sum(tt.chump)/len(tt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced = pd.concat([\n",
    "    tr[tr.chump],\n",
    "    tr[~tr.chump].sample(n=9 * len(tr[tr.chump]))\n",
    "])\n",
    "# Train on balanced data (10% chumps)\n",
    "X = balanced.drop(columns=['chump', 'target'])\n",
    "Y = balanced['chump']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Balanced chumps: ', sum(balanced.chump) / len(balanced))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=100, max_depth=7)\n",
    "clf.fit(X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now retrain the regressor on only \"non-chumps\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tr[~tr.chump].drop(columns=['chump', 'target'])\n",
    "Y = tr[~tr.chump]['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfr = RandomForestRegressor(max_depth=5, random_state=0, n_estimators=100)\n",
    "rfr.fit(X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply trained models to full train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tt.drop(columns=['chump', 'target'])\n",
    "Y = tt['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['pred_chump'] = clf.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chumps = pd.DataFrame(X[X.pred_chump])\n",
    "nonchumps = pd.DataFrame(X[~X.pred_chump])\n",
    "chumps.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chumps['pred_target'] = -33.219281\n",
    "chumps.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X.loc[X.pred_chump, 'pred_target'] = -33.219281"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonchumps['pred_target'] = rfr.predict(nonchumps.drop(columns='pred_chump'))\n",
    "nonchumps.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X.loc[~X.pred_chump, 'pred_target'] = rfr.predict(X[~X.pred_chump].drop(columns=['pred_chump', 'pred_target']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.concat([chumps, nonchumps])\n",
    "X = X.join(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(mean_squared_error(X.target, X.pred_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X[X.pred_chump])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(X.target < -20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(X.pred_chump != (X.target < -20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into tr for training and tt for final test\n",
    "# tr and tt will maintain the same chump/nonchump ratio\n",
    "train['chump'] = train['target'] < -20\n",
    "chumps = train[train.chump]\n",
    "nonchumps = train[~train.chump]\n",
    "tr_chumps, tt_chumps = train_test_split(chumps, test_size=0.3)\n",
    "tr_nonchumps, tt_nonchumps = train_test_split(nonchumps, test_size=0.3)\n",
    "tr = pd.concat([tr_chumps, tr_nonchumps])\n",
    "tt = pd.concat([tt_chumps, tt_nonchumps])\n",
    "\n",
    "ranges = [1, 3, 5, 7, 10, 15, None]\n",
    "models = [\n",
    "    {'rmd': rmd,\n",
    "     'rmf': rmf,\n",
    "     'cmd': cmd,\n",
    "     'cmf': cmf,\n",
    "     'score': np.nan} \n",
    "    for rmd in ranges\n",
    "    for rmf in ranges\n",
    "    for cmd in ranges\n",
    "    for cmf in ranges\n",
    "]\n",
    "\n",
    "for i, m in enumerate(models):\n",
    "    # Train Classifier (rebalanced tr set)\n",
    "    balanced = pd.concat([\n",
    "        tr[tr.chump],\n",
    "        tr[~tr.chump].sample(n=9 * len(tr[tr.chump]))\n",
    "    ])\n",
    "    # Train on balanced data (10% chumps)\n",
    "    X = balanced.drop(columns=['chump', 'target'])\n",
    "    Y = balanced['chump']\n",
    "    clf = RandomForestClassifier(\n",
    "        n_estimators=  100,\n",
    "        max_depth=     m['cmd'],\n",
    "        max_features=  m['cmf'],\n",
    "        random_state=  0)\n",
    "    clf.fit(X, Y)\n",
    "    \n",
    "    # Train Regressor (full tr set)\n",
    "    X = tr[~tr.chump].drop(columns=['chump', 'target'])\n",
    "    Y = tr[~tr.chump]['target']\n",
    "    rfr = RandomForestRegressor(\n",
    "        n_estimators=  100,\n",
    "        max_depth=     m['rmd'],\n",
    "        max_features=  m['rmf'],\n",
    "        random_state=  0)\n",
    "    rfr.fit(X, Y)\n",
    "    \n",
    "    # Apply models to tt holdout set\n",
    "    X = tt.drop(columns=['chump', 'target'])\n",
    "    Y = tt['target']\n",
    "    X['pred_chump'] = clf.predict(X)\n",
    "    chumps = pd.DataFrame(X[X.pred_chump])\n",
    "    nonchumps = pd.DataFrame(X[~X.pred_chump])\n",
    "    chumps['pred_target'] = -33.219281\n",
    "    nonchumps['pred_target'] = rfr.predict(nonchumps.drop(columns='pred_chump'))\n",
    "    X = pd.concat([chumps, nonchumps])\n",
    "    X = X.join(Y)\n",
    "    m['score'] = np.sqrt(mean_squared_error(X.target, X.pred_target))\n",
    "    print(f'== {np.round((i + 1) / len(models) * 100, 2)}% ==\\r', end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(models, key = lambda x: x['score'])[:15]t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>card_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>C_ID_0ab67a22ab</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_ID_130fd0cbdd</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_ID_b709037bc5</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_ID_d27d835a9f</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_ID_2b5e3df5c2</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                target\n",
       "card_id               \n",
       "C_ID_0ab67a22ab    NaN\n",
       "C_ID_130fd0cbdd    NaN\n",
       "C_ID_b709037bc5    NaN\n",
       "C_ID_d27d835a9f    NaN\n",
       "C_ID_2b5e3df5c2    NaN"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['chump'] = train['target'] < -20\n",
    "# Train Classifier (rebalanced tr set)\n",
    "balanced = pd.concat([\n",
    "    train[train.chump],\n",
    "    train[~train.chump].sample(n=9 * len(train[train.chump]))\n",
    "])\n",
    "# Train on balanced data (10% chumps)\n",
    "X = balanced.drop(columns=['chump', 'target'])\n",
    "Y = balanced['chump']\n",
    "clf = RandomForestClassifier(\n",
    "    n_estimators=  1000,\n",
    "    max_depth=     3,\n",
    "    max_features=  3,\n",
    "    random_state=  0)\n",
    "clf.fit(X, Y)\n",
    "\n",
    "# Train Regressor (full tr set)\n",
    "X = train[~train.chump].drop(columns=['chump', 'target'])\n",
    "Y = train[~train.chump]['target']\n",
    "rfr = RandomForestRegressor(\n",
    "    n_estimators=  1000,\n",
    "    max_depth=     10,\n",
    "    max_features=  15,\n",
    "    random_state=  0)\n",
    "rfr.fit(X, Y)\n",
    "\n",
    "# Apply models to tt holdout set\n",
    "test['pred_chump'] = clf.predict(test)\n",
    "chumps = pd.DataFrame(test[test.pred_chump])\n",
    "nonchumps = pd.DataFrame(test[~test.pred_chump])\n",
    "chumps['pred_target'] = -33.219281\n",
    "nonchumps['pred_target'] = rfr.predict(nonchumps.drop(columns='pred_chump'))\n",
    "test = pd.concat([chumps, nonchumps])\n",
    "predictions = pd.DataFrame(test['pred_target'], index=test.index)\n",
    "predictions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>card_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>C_ID_0ab67a22ab</th>\n",
       "      <td>-0.272179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_ID_130fd0cbdd</th>\n",
       "      <td>-0.450876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_ID_b709037bc5</th>\n",
       "      <td>0.002175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_ID_d27d835a9f</th>\n",
       "      <td>-0.293506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_ID_2b5e3df5c2</th>\n",
       "      <td>-0.209106</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   target\n",
       "card_id                  \n",
       "C_ID_0ab67a22ab -0.272179\n",
       "C_ID_130fd0cbdd -0.450876\n",
       "C_ID_b709037bc5  0.002175\n",
       "C_ID_d27d835a9f -0.293506\n",
       "C_ID_2b5e3df5c2 -0.209106"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = pd.DataFrame(test['pred_target'], index=test.index)\n",
    "predictions.columns = ['target']\n",
    "predictions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.to_csv('../submission_stacked_rf.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forget the stacked model - tune RFR to full training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== 100.0% ==\r"
     ]
    }
   ],
   "source": [
    "train['chump'] = train['target'] < -20\n",
    "chumps = train[train.chump]\n",
    "nonchumps = train[~train.chump]\n",
    "tr_chumps, tt_chumps = train_test_split(chumps, test_size=0.3)\n",
    "tr_nonchumps, tt_nonchumps = train_test_split(nonchumps, test_size=0.3)\n",
    "tr = pd.concat([tr_chumps, tr_nonchumps]).drop(columns='chump')\n",
    "tt = pd.concat([tt_chumps, tt_nonchumps]).drop(columns='chump')\n",
    "\n",
    "ranges = [1, 3, 5, 7, 10, 15, None]\n",
    "models = [\n",
    "    {'rmd': rmd,\n",
    "     'rmf': rmf,\n",
    "     'score': np.nan} \n",
    "    for rmd in ranges\n",
    "    for rmf in ranges\n",
    "]\n",
    "\n",
    "for i, m in enumerate(models):\n",
    "    X = tr.drop(columns='target')\n",
    "    Y = tr['target']\n",
    "    rfr = RandomForestRegressor(\n",
    "        n_estimators=  100,\n",
    "        max_depth=     m['rmd'],\n",
    "        max_features=  m['rmf'],\n",
    "        random_state=  0)\n",
    "    rfr.fit(X, Y)\n",
    "    \n",
    "    # Apply models to tt holdout set\n",
    "    X = tt.drop(columns='target')\n",
    "    Y = tt['target']\n",
    "    X['pred_target'] = rfr.predict(X)\n",
    "    X = X.join(Y)\n",
    "    m['score'] = np.sqrt(mean_squared_error(X.target, X.pred_target))\n",
    "    print(f'== {np.round((i + 1) / len(models) * 100, 2)}% ==\\r', end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'rmd': 10, 'rmf': 15, 'score': 3.7395660454228663},\n",
       " {'rmd': 10, 'rmf': 10, 'score': 3.7422055659302345},\n",
       " {'rmd': 7, 'rmf': 15, 'score': 3.7426121888584363},\n",
       " {'rmd': 7, 'rmf': None, 'score': 3.744888422483514},\n",
       " {'rmd': 10, 'rmf': None, 'score': 3.744935306206704},\n",
       " {'rmd': 10, 'rmf': 7, 'score': 3.746716717502648},\n",
       " {'rmd': 15, 'rmf': 7, 'score': 3.747300911105606},\n",
       " {'rmd': 7, 'rmf': 10, 'score': 3.7477582995558754},\n",
       " {'rmd': 15, 'rmf': 5, 'score': 3.7505094016742904},\n",
       " {'rmd': 15, 'rmf': 10, 'score': 3.752290507996586},\n",
       " {'rmd': 5, 'rmf': None, 'score': 3.7522945150526223},\n",
       " {'rmd': 5, 'rmf': 15, 'score': 3.7543497787056563},\n",
       " {'rmd': 15, 'rmf': 15, 'score': 3.7547762994379665},\n",
       " {'rmd': 7, 'rmf': 7, 'score': 3.7562905575751566},\n",
       " {'rmd': 10, 'rmf': 5, 'score': 3.7565375557534546}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(models, key = lambda x: x['score'])[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['feature_1', 'feature_2', 'feature_3', 'tof', 'recency', 'frequency',\n",
       "       'log_freq', 'amt', 'avg_amt', 'charge_per_day', 'log_charge_per_day',\n",
       "       'max_amt', 'n_declines', 'log_n_declines', 'prop_new', 'merch_cat_1_Y',\n",
       "       'merch_cat_2_1', 'merch_cat_2_2', 'merch_cat_2_3', 'merch_cat_2_4',\n",
       "       'merch_cat_2_5', 'amt_total_amin', 'amt_total_mean', 'amt_total_amax',\n",
       "       'NDR_amin', 'NDR_mean', 'NDR_amax', 'n_new_merchants_mean',\n",
       "       'n_total_merchants_amax'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best model has `max_depth=10` and `max_features=15`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Index(...) must be called with a collection of some kind, 'target' was passed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-2f6af898497f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m         random_state=  0)\n\u001b[1;32m      8\u001b[0m \u001b[0mrfr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrfr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'target'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#.to_csv('../submission.csv')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    422\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m                 mgr = init_ndarray(data, index, columns, dtype=dtype,\n\u001b[0;32m--> 424\u001b[0;31m                                    copy=copy)\n\u001b[0m\u001b[1;32m    425\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m         \u001b[0;31m# For data is list-like, or Iterable (will consume into list)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36minit_ndarray\u001b[0;34m(values, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    156\u001b[0m                 \u001b[0mraise_with_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m     \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_axes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m     \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36m_get_axes\u001b[0;34m(N, K, index, columns)\u001b[0m\n\u001b[1;32m    373\u001b[0m         \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mibase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 375\u001b[0;31m         \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    376\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mensure_index\u001b[0;34m(index_like, copy)\u001b[0m\n\u001b[1;32m   5375\u001b[0m             \u001b[0mindex_like\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex_like\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5376\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5377\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex_like\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5379\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m__new__\u001b[0;34m(cls, data, dtype, copy, name, fastpath, tupleize_cols, **kwargs)\u001b[0m\n\u001b[1;32m    466\u001b[0m                          **kwargs)\n\u001b[1;32m    467\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 468\u001b[0;31m             \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_scalar_data_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    469\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtupleize_cols\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_list_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_scalar_data_error\u001b[0;34m(cls, data)\u001b[0m\n\u001b[1;32m   3796\u001b[0m         raise TypeError('{0}(...) must be called with a collection of some '\n\u001b[1;32m   3797\u001b[0m                         'kind, {1} was passed'.format(cls.__name__,\n\u001b[0;32m-> 3798\u001b[0;31m                                                       repr(data)))\n\u001b[0m\u001b[1;32m   3799\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3800\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Index(...) must be called with a collection of some kind, 'target' was passed"
     ]
    }
   ],
   "source": [
    "X = train.drop(columns=['target', 'chump'])\n",
    "Y = train['target']\n",
    "rfr = RandomForestRegressor(\n",
    "        n_estimators=  1000,\n",
    "        max_depth=     10,\n",
    "        max_features=  15,\n",
    "        random_state=  0)\n",
    "rfr.fit(X, Y)\n",
    "pd.DataFrame(rfr.predict(test), index=test.index, columns='target').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>card_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>C_ID_0ab67a22ab</th>\n",
       "      <td>-0.788704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_ID_130fd0cbdd</th>\n",
       "      <td>-0.453762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_ID_b709037bc5</th>\n",
       "      <td>0.004535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_ID_d27d835a9f</th>\n",
       "      <td>-0.286328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_ID_2b5e3df5c2</th>\n",
       "      <td>-0.293103</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   target\n",
       "card_id                  \n",
       "C_ID_0ab67a22ab -0.788704\n",
       "C_ID_130fd0cbdd -0.453762\n",
       "C_ID_b709037bc5  0.004535\n",
       "C_ID_d27d835a9f -0.286328\n",
       "C_ID_2b5e3df5c2 -0.293103"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = pd.DataFrame(rfr.predict(test), index=test.index, columns=['target'])\n",
    "predictions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.to_csv('../submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
